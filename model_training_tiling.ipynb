{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from torchinfo import summary\n",
    "\n",
    "from src.datasets import BiosensorDataset, create_datasets\n",
    "from src.model_parts import *\n",
    "from src.models import *\n",
    "# from src.train_tiling import train_model, evaluate\n",
    "from src.train import train_model\n",
    "from src.evaluate import evaluate\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "batch_size = 16\n",
    "upscale_factor = 4\n",
    "\n",
    "config = {\n",
    "    'path': 'C:/onlab_git/Onlab/data_with_centers/',\n",
    "    'mask_type': bool,\n",
    "    'augment': False,\n",
    "    'noise': 0.0,\n",
    "    'dilation': 0,\n",
    "    'tiling': True,\n",
    "    'tiling_ratio': 2,\n",
    "}\n",
    "\n",
    "create_dataset_args = {\n",
    "    'train_percent': 0.59,\n",
    "    'test_percent': 0.215,\n",
    "}\n",
    "\n",
    "calc_config = {\n",
    "    'biosensor_length': 8,\n",
    "    'mask_size': 80 * upscale_factor,\n",
    "    'input_scaling': False,\n",
    "    'upscale_mode': 'nearest',\n",
    "}\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = create_datasets(config, create_dataset_args, calc_config)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print('Train size:', len(train_dataset))\n",
    "print('Validation size:', len(val_dataset))\n",
    "print('Test size:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet(n_channels=calc_config['biosensor_length'], n_classes=1, down_conv=SingleConv, up_conv=SingleConv, bilinear=False)\n",
    "model = SRUNet4(n_channels=calc_config['biosensor_length'], n_classes=1, down_conv=SingleConv, up_conv=SingleConv, bilinear=False)\n",
    "model = model.to(device)\n",
    "print(model.__class__.__name__)\n",
    "project_name = \"Testing tiling\"\n",
    "model_name = \"\"\n",
    "\n",
    "model_summary = summary(model)\n",
    "print(model_summary.trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_model(\n",
    "        model,\n",
    "        project_name,\n",
    "        model_name,\n",
    "        device,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        learning_rate=0.03,\n",
    "        epochs=5,\n",
    "        checkpoint_dir='test_saves',\n",
    "        amp=True,\n",
    "        wandb_logging=False,\n",
    "        tile_ratio=config['tiling_ratio'],\n",
    "    )\n",
    "except torch.cuda.OutOfMemoryError:\n",
    "    torch.cuda.empty_cache()\n",
    "    print('Detected OutOfMemoryError!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "model_summary = summary(model, depth=4)\n",
    "print(model_summary)\n",
    "# print(model_summary.total_params)\n",
    "# print(model_summary.trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load(\"test_saves/checkpoint_epoch14.pth\")\n",
    "# Get the learning rate and remove it from the checkpoint\n",
    "lr = checkpoint.pop('learning_rate')\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(checkpoint)\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "evaluate_after_training(model, val_loader, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best model for production\n",
    "# model = UNet8(n_channels=8, n_classes=1)\n",
    "# checkpoint = torch.load(\"checkpoints/checkpoint_8_4_85.pth\")\n",
    "# lr = checkpoint.pop('learning_rate')\n",
    "# model.load_state_dict(checkpoint)\n",
    "\n",
    "# torch.jit.script(model).save('saved_models/srunet8_len8_40dice.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, labels) in enumerate(test_loader):\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    batch_size, tile_num, channels, height, width = data.shape\n",
    "    data = data.view(batch_size * tile_num, channels, height, width)\n",
    "\n",
    "    predictions = model(data)\n",
    "\n",
    "    predictions = predictions.view(batch_size, tile_num, 1, height, width)\n",
    "    data = data.view(batch_size, tile_num, channels, height, width)\n",
    "\n",
    "    binary_predictions = (torch.nn.functional.sigmoid(predictions) > 0.5)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        # index = (batch_idx * len(data) + i + 1)\n",
    "        # print(index)\n",
    "\n",
    "        label = np.squeeze(labels[i])\n",
    "        binary_prediction = np.squeeze(binary_predictions[i])\n",
    "        label = merge_tiles(label)\n",
    "        binary_prediction = merge_tiles(binary_prediction)\n",
    "        d = merge_tiles(data[i,:,-1])\n",
    "        prediction = merge_tiles(predictions[i, :, 0])\n",
    "\n",
    "        plot_results(d, label, prediction, binary_prediction)\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loader_tiles_data(test_loader, 'Test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
