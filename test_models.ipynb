{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from torchinfo import summary\n",
    "\n",
    "from src.datasets import BiosensorDataset, create_datasets\n",
    "from src.test_models.test_parts import *\n",
    "from src.test_models.modular_models import *\n",
    "from src.train import train_model\n",
    "from src.evaluate import evaluate\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, down_conv, up_conv, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = down_conv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128, down_conv)\n",
    "        self.down2 = Down(128, 256, down_conv)\n",
    "        self.down3 = Down(256, 512, down_conv)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor, down_conv)\n",
    "        self.up1 = Up(1024, 512 // factor, up_conv, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, up_conv, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, up_conv, bilinear)\n",
    "        self.up4 = Up(128, 64, up_conv, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class UNet4(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, down_conv, up_conv, bilinear=False):\n",
    "        super(UNet4, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        \n",
    "        self.inc = down_conv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128, down_conv)\n",
    "        self.down2 = Down(128, 256, down_conv)\n",
    "        self.down3 = Down(256, 512, down_conv)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor, down_conv)\n",
    "        self.up1 = Up(1024, 512 // factor, up_conv, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, up_conv, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, up_conv, bilinear)\n",
    "        self.up4 = Up(128, 64 // factor, up_conv, bilinear)\n",
    "        self.up5 = Up(64, 32 // factor, up_conv, bilinear)\n",
    "        self.up6 = Up(32, 16, up_conv, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "\n",
    "        self.up_s1=Upscaling(64, 32, up_conv)\n",
    "        self.up_s2=Upscaling(32, 16, up_conv)\n",
    "\n",
    "    def forward(self, xs):\n",
    "        x1 = self.inc(xs)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "\n",
    "        # Upsample \"negative\" layers\n",
    "        x0=self.up_s1(x1)\n",
    "        x_1=self.up_s2(x0)\n",
    "        \n",
    "        x = self.up5(x, x0)\n",
    "        x = self.up6(x, x_1)\n",
    "        x = self.outc(x)\n",
    "        return x\n",
    "\n",
    "class UNet8(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, down_conv, up_conv, bilinear=False):\n",
    "        super(UNet8, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = down_conv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128, down_conv)\n",
    "        self.down2 = Down(128, 256, down_conv)\n",
    "        self.down3 = Down(256, 512, down_conv)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor, down_conv)\n",
    "        self.up1 = Up(1024, 512 // factor, up_conv, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, up_conv, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, up_conv, bilinear)\n",
    "        self.up4 = Up(128, 64 // factor, up_conv, bilinear)\n",
    "        self.up5 = Up(64, 32 // factor, up_conv, bilinear)\n",
    "        self.up6 = Up(32, 16 // factor, up_conv, bilinear)\n",
    "        self.up7 = Up(16, 8, up_conv, bilinear)\n",
    "        self.outc = OutConv(8, n_classes)\n",
    "\n",
    "        self.up_s1=Upscaling(64, 32)\n",
    "        self.up_s2=Upscaling(32, 16)\n",
    "        self.up_s3=Upscaling(16, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "\n",
    "        x0=self.up_s1(x1)\n",
    "        x_1=self.up_s2(x0)\n",
    "        x_2=self.up_s3(x_1)\n",
    "\n",
    "        x = self.up5(x, x0)\n",
    "        x = self.up6(x, x_1)\n",
    "        x = self.up7(x, x_2)\n",
    "        x = self.outc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/onlab_git/Onlab/data_with_centers/'\n",
    "train_percent = 0.59\n",
    "test_percent = 0.215\n",
    "\n",
    "files = os.listdir(data_path)\n",
    "train_size = int(train_percent * len(files))\n",
    "val_size = len(files) - train_size\n",
    "if test_percent > 0:\n",
    "    test_size = int(test_percent * len(files))\n",
    "    val_size = val_size - test_size\n",
    "\n",
    "print('Train size:', train_size)\n",
    "print('Validation size:', val_size)\n",
    "print('Test size:', test_size)\n",
    "\n",
    "\n",
    "# tran, val, test: train %, test %\n",
    "# 128, 16, 19: .79, .12\n",
    "# 112, 24, 27: .69, .17\n",
    "# 96, 32, 35: .59, .215     this is the best - wandb logs\n",
    "# 80, 40, 43: .495 .265\n",
    "# 64, 48, 51: .395 .315\n",
    "# 48, 48, 67: .3 .415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(config):\n",
    "    path = config['path']\n",
    "    train_percent = config['train_percent']\n",
    "    mask_type = config['mask_type']\n",
    "    test_percent = config.get('test_percent', 0)\n",
    "    biosensor_length = config.get('biosensor_length', 8)\n",
    "    mask_size = config.get('mask_size', 80)\n",
    "    augment = config.get('augment', False)\n",
    "    noise = config.get('noise', 0.0)\n",
    "    dilation = config.get('dilation', 0)\n",
    "    input_scaling = config.get('input_scaling', False)\n",
    "    upscale_mode = config.get('upscale_mode', 'nearest')\n",
    "    print(upscale_mode)\n",
    "    # Your function implementation here\n",
    "    pass\n",
    "\n",
    "# Usage\n",
    "config = {\n",
    "    'path': 'path/to/data',\n",
    "    'train_percent': 0.8,\n",
    "    'mask_type': 'bool',\n",
    "    'test_percent': 0.1,\n",
    "    'biosensor_length': 128,\n",
    "    'mask_size': 80,\n",
    "    'augment': True,\n",
    "    'noise': 0.1,\n",
    "    'dilation': 0,\n",
    "    'input_scaling': False,\n",
    "    'upscale_mode': 'bilinear'\n",
    "}\n",
    "\n",
    "create_datasets(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_datasets(\n",
    "# path, train_percent, test_percent=0,\n",
    "# mask_type=bool, biosensor_length=8, mask_size=80, \n",
    "# augment=False, noise=0.0, dilation=0, input_scaling=False, upscale_mode='nearest', tiling=False, tiling_ratio=1)\n",
    "\n",
    "# class BiosensorDataset(Dataset): def __init__(\n",
    "# self, path, files, mean, std, \n",
    "# mask_type=bool, biosensor_length=8, mask_size=80, \n",
    "# augment=False, noise=0.0, dilation=0, input_scaling=False, upscale_mode='nearest', tiling=False, tiling_ratio=1)\n",
    "\n",
    "config = {\n",
    "    'path': 'C:/onlab_git/Onlab/data_with_centers/',\n",
    "    'mask_type': bool,\n",
    "    'augment': False,\n",
    "    'noise': 0.0,\n",
    "    'dilation': 0,\n",
    "    'tiling': False,\n",
    "    'tiling_ratio': 1\n",
    "}\n",
    "\n",
    "calc_config = {\n",
    "    'biosensor_length': 8,\n",
    "    'mask_size': 80,\n",
    "    'input_scaling': False,\n",
    "    'upscale_mode': 'nearest',\n",
    "}\n",
    "\n",
    "create_dataset_args = {\n",
    "    'train_percent': 0.59,\n",
    "    'test_percent': 0.215,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "data_path = 'C:/onlab_git/Onlab/data_with_centers/'\n",
    "checkpoint_dir = 'test_saves'\n",
    "train_percent = 0.59\n",
    "test_percent = 0.215\n",
    "batch_size = 16\n",
    "bio_len = 8\n",
    "upscale_factor = 8\n",
    "mask_size = 80 * upscale_factor\n",
    "input_scaling = False\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = create_datasets(data_path, train_percent, bool, test_percent=test_percent, \n",
    "                                biosensor_length=bio_len, mask_size=mask_size, augment=True, noise=0.0,\n",
    "                                dilation=0, input_scaling=input_scaling, upscale_mode='nearest') # nearest bilinear bicubic\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print('Train size:', len(train_dataset))\n",
    "print('Validation size:', len(val_dataset))\n",
    "print('Test size:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Models to test:\n",
    "- UNet with convolution and bilinear upsampling\n",
    "- SRUNet4 with convolution and bilinear upsampling\n",
    "- SRUNet8 with convolution and bilinear upsampling\n",
    "- UNet with bigger inputs\n",
    "- mid channels\n",
    "- Single, Double, Triple, Quadruple Conv layers\n",
    "\n",
    "- layer, channel, kernel size changes\n",
    "___________________________________________________\n",
    "\n",
    "- UNet_80_double_conv\n",
    "- UNet_80_double_bilin\n",
    "\n",
    "- UNet_80_single_conv\n",
    "\n",
    "- Unet_160_double_conv\n",
    "- UNet_320_double_conv\n",
    "\n",
    "- SRUNet4_80_single_conv\n",
    "- SRUNet4_80_single_bilin\n",
    "\n",
    "- SRUNet8_80_single_conv\n",
    "- SRUNet8_80_single_bilin\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet8(n_channels=bio_len, n_classes=1, down_conv=SingleConv, up_conv=SingleConv, bilinear=False)\n",
    "# model = UNet8(n_channels=bio_len, n_classes=1, down_conv=DoubleConv, up_conv=DoubleConv, bilinear=False)\n",
    "# model = UNet8(n_channels=bio_len, n_classes=1, down_conv=TripleConv, up_conv=TripleConv, bilinear=False)\n",
    "model = model.to(device)\n",
    "print(model.__class__.__name__)\n",
    "project_name = \"Testing SR models\"\n",
    "# model_name = \"UNet_320_triple_conv_bilin\"\n",
    "# model_name = \"SRUNet4_80_single_bilin\"\n",
    "model_name = \"SRUNet8_80_triple_bilin\"\n",
    "\n",
    "model_summary = summary(model)\n",
    "print(model_summary.trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_model(\n",
    "        model,\n",
    "        project_name,\n",
    "        model_name,\n",
    "        device,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        learning_rate=0.03,\n",
    "        epochs=20,\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        amp=True,\n",
    "        wandb_logging=True\n",
    "    )\n",
    "except torch.cuda.OutOfMemoryError:\n",
    "    torch.cuda.empty_cache()\n",
    "    print('Detected OutOfMemoryError!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "model_summary = summary(model, depth=4)\n",
    "print(model_summary)\n",
    "# print(model_summary.total_params)\n",
    "# print(model_summary.trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_after_training(model, val_loader, test_loader, device):\n",
    "    val_dice_score, val_detection_rate = evaluate(model, val_loader, device)\n",
    "    dice_score, detection_rate = evaluate(model, test_loader, device)\n",
    "    print(f'Validation dice score: {val_dice_score}, Detection rate: {val_detection_rate}')\n",
    "    print(f'Test dice score: {dice_score}, Detection rate: {detection_rate}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load(\"test_saves/checkpoint_epoch20.pth\")\n",
    "# Get the learning rate and remove it from the checkpoint\n",
    "lr = checkpoint.pop('learning_rate')\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(checkpoint)\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "evaluate_after_training(model, val_loader, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best model for production\n",
    "# model = UNet8(n_channels=8, n_classes=1)\n",
    "# checkpoint = torch.load(\"checkpoints/checkpoint_8_4_85.pth\")\n",
    "# lr = checkpoint.pop('learning_rate')\n",
    "# model.load_state_dict(checkpoint)\n",
    "\n",
    "# torch.jit.script(model).save('saved_models/srunet8_len8_40dice.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(bio, mask, prediction, binary_prediction):\n",
    "    plt.figure(figsize=(30, 10))\n",
    "\n",
    "    colored_mask = np.zeros((mask.shape[0], mask.shape[1], 4), dtype=np.float32)\n",
    "    colored_mask[mask == 1] = [1, 0, 0, 1]\n",
    "    colored_mask[mask == 0] = [0, 0, 0, 0]\n",
    "\n",
    "    colored_prediction = np.zeros((mask.shape[0], mask.shape[1], 4), dtype=np.float32)\n",
    "    colored_prediction[binary_prediction == 1] = [0, 0, 1, 1]\n",
    "    colored_prediction[binary_prediction == 0] = [0, 0, 0, 0]\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(bio, cmap='gray')\n",
    "    plt.imshow(colored_mask, alpha=0.6)\n",
    "    plt.title('Biosensor with mask')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(prediction, cmap='gray')\n",
    "    plt.imshow(colored_prediction, alpha=0.6)\n",
    "    plt.title('Prediction with the binary')\n",
    "\n",
    "    intercection = np.zeros((mask.shape[0], mask.shape[1], 4), dtype=np.float32)\n",
    "    intercection[(mask == 1) & (binary_prediction == 1)] = [0, 1, 0, 1]\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    # plt.imshow(bio, cmap='gray')\n",
    "    plt.imshow(colored_mask)\n",
    "    plt.imshow(colored_prediction)\n",
    "    plt.imshow(intercection)\n",
    "    plt.title('Label and Prediction overlap')\n",
    "    \n",
    "    red_patch = mpatches.Patch(color=[1, 0, 0, 1], label='Mask')\n",
    "    blue_patch = mpatches.Patch(color=[0, 0, 1, 1], label='Prediction')\n",
    "    green_patch = mpatches.Patch(color=[0, 1, 0, 1], label='Overlap')\n",
    "\n",
    "    plt.legend(handles=[red_patch, blue_patch, green_patch], loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, labels) in enumerate(test_loader):\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    predictions = model(data)\n",
    "\n",
    "    binary_predictions = (torch.nn.functional.sigmoid(predictions) > 0.5)\n",
    "    binary_predictions = binary_predictions.cpu().detach().numpy()\n",
    "\n",
    "    labels = labels.cpu().numpy()\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        index = (batch_idx * len(data) + i + 1)\n",
    "        # print(index)\n",
    "        label = np.squeeze(labels[i])\n",
    "        binary_prediction = np.squeeze(binary_predictions[i])\n",
    "\n",
    "        plot_results(data[i][-1].cpu().detach().numpy(), label, np.squeeze(predictions[i]), binary_prediction)\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loader_data(loader, title):\n",
    "    for batch_idx, (data, labels) in enumerate(loader):\n",
    "        # Move the data and labels to the CPU\n",
    "        data = data.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "\n",
    "        # if batch_idx == 1:\n",
    "        #     break\n",
    "\n",
    "        # Plot each image in the batch\n",
    "        for i in range(len(data)):\n",
    "            index = (batch_idx * len(data) + i + 1)\n",
    "\n",
    "            plt.figure(figsize=(20, 10))\n",
    "\n",
    "            # Plot the input image\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(data[i][-1], cmap='gray')\n",
    "            plt.title(f'{title} - Image {index} ')\n",
    "\n",
    "            # Plot the label\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(labels[i], cmap='gray')\n",
    "            plt.title(f'{title} - Label {index}')\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(data[i][-1], cmap='gray')\n",
    "            plt.imshow(labels[i], cmap='Reds', alpha=0.25)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "plot_loader_data(test_loader, 'Test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
