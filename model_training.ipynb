{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "\n",
    "from src.datasets import BiosensorDataset, create_datasets\n",
    "from src.model_parts import *\n",
    "from src.models import *\n",
    "from src.train import train_model\n",
    "from src.evaluate import evaluate\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "batch_size = 16\n",
    "upscale_factor = 4\n",
    "\n",
    "config = {\n",
    "    'path': 'C:/onlab_git/Onlab/data_with_centers/',\n",
    "    'mask_type': bool,\n",
    "    'augment': True,\n",
    "    'noise': 0.0,\n",
    "    'dilation': 0,\n",
    "    'tiling': False,\n",
    "    'tiling_ratio': 1,\n",
    "}\n",
    "\n",
    "create_dataset_args = {\n",
    "    'train_percent': 0.59,\n",
    "    'test_percent': 0.215,\n",
    "}\n",
    "\n",
    "calc_config = {\n",
    "    'biosensor_length': 8,\n",
    "    'mask_size': 80 * upscale_factor,\n",
    "    'input_scaling': False,\n",
    "    'upscale_mode': 'nearest',\n",
    "}\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = create_datasets(config, create_dataset_args, calc_config)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print('Train size:', len(train_dataset))\n",
    "print('Validation size:', len(val_dataset))\n",
    "print('Test size:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet4(n_channels=calc_config['biosensor_length'], n_classes=1, down_conv=DoubleConv, up_conv=DoubleConv, bilinear=False)\n",
    "\n",
    "model = model.to(device)\n",
    "print(model.__class__.__name__)\n",
    "project_name = \"\"\n",
    "model_name = \"\"\n",
    "\n",
    "model_summary = summary(model)\n",
    "print(model_summary.trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_model(\n",
    "        model,\n",
    "        project_name,\n",
    "        model_name,\n",
    "        device,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        learning_rate=0.01,\n",
    "        epochs=10,\n",
    "        checkpoint_dir='test_saves',\n",
    "        amp=True,\n",
    "        wandb_logging=False,\n",
    "        tile_ratio=config['tiling_ratio'],\n",
    "    )\n",
    "except torch.cuda.OutOfMemoryError:\n",
    "    torch.cuda.empty_cache()\n",
    "    print('Detected OutOfMemoryError!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "model_summary = summary(model, depth=4)\n",
    "print(model_summary)\n",
    "# print(model_summary.total_params)\n",
    "# print(model_summary.trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load(\"test_saves/checkpoint_epoch18.pth\")\n",
    "# Get the learning rate and remove it from the checkpoint\n",
    "lr = checkpoint.pop('learning_rate')\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(checkpoint)\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "evaluate_after_training(model, val_loader, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best model for production\n",
    "# model = UNet8(n_channels=8, n_classes=1)\n",
    "# checkpoint = torch.load(\"checkpoints/checkpoint_8_4_85.pth\")\n",
    "# lr = checkpoint.pop('learning_rate')\n",
    "# model.load_state_dict(checkpoint)\n",
    "\n",
    "# torch.jit.script(model).save('saved_models/srunet8_len8_40dice.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, labels) in enumerate(test_loader):\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    predictions = model(data)\n",
    "\n",
    "    binary_predictions = (torch.nn.functional.sigmoid(predictions) > 0.5)\n",
    "\n",
    "    # binary_predictions = binary_predictions.cpu().detach().numpy()\n",
    "    # labels = labels.cpu().numpy()\n",
    "    # predictions = predictions.cpu().detach().numpy()\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        # index = (batch_idx * len(data) + i + 1)\n",
    "        # print(index)\n",
    "        label = np.squeeze(labels[i])\n",
    "        binary_prediction = np.squeeze(binary_predictions[i])\n",
    "\n",
    "        plot_results(data[i][-1], label, np.squeeze(predictions[i]), binary_prediction)\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loader_data(test_loader, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/onlab_git/Onlab/data_with_centers/'\n",
    "train_percent = 0.59\n",
    "test_percent = 0.215\n",
    "\n",
    "files = os.listdir(data_path)\n",
    "train_size = int(train_percent * len(files))\n",
    "val_size = len(files) - train_size\n",
    "if test_percent > 0:\n",
    "    test_size = int(test_percent * len(files))\n",
    "    val_size = val_size - test_size\n",
    "\n",
    "print('Train size:', train_size)\n",
    "print('Validation size:', val_size)\n",
    "print('Test size:', test_size)\n",
    "\n",
    "\n",
    "# tran, val, test: train %, test %\n",
    "# 128, 16, 19: .79, .12\n",
    "# 112, 24, 27: .69, .17\n",
    "# 96, 32, 35: .59, .215     this is the best - wandb logs\n",
    "# 80, 40, 43: .495 .265\n",
    "# 64, 48, 51: .395 .315\n",
    "# 48, 48, 67: .3 .415"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SRUNet4_80_single_double_conv:  \n",
    "Validation dice score: 0.3975284993648529, Detection rate: 0.7234726688102894  \n",
    "Test dice score: 0.37295183539390564, Detection rate: 0.6732588134135855\n",
    "\n",
    "SRUNet4_80_single_double_bilinear:  \n",
    "Validation dice score: 0.37835413217544556, Detection rate: 0.6852090032154341  \n",
    "Test dice score: 0.35115525126457214, Detection rate: 0.6213814846660934\n",
    "\n",
    "SRUNet4_80_single_triple_conv:  \n",
    "Validation dice score: 0.3669853210449219, Detection rate: 0.6864951768488746  \n",
    "Test dice score: 0.33828431367874146, Detection rate: 0.6423043852106621\n",
    "\n",
    "SRUNet4_80_double_triple_conv:  \n",
    "Validation dice score: 0.36824554204940796, Detection rate: 0.6520900321543408  \n",
    "Test dice score: 0.3549373149871826, Detection rate: 0.6102034967039266\n",
    "\n",
    "SRUNet4_80_double_single_conv:  \n",
    "Validation dice score: 0.40089017152786255, Detection rate: 0.7331189710610932  \n",
    "Test dice score: 0.37190067768096924, Detection rate: 0.6798509601605044"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNet_80_double_conv:  \n",
    "Validation dice score: 0.43662238121032715, Detection rate: 0.8377581120943953  \n",
    "Test dice score: 0.4221133887767792, Detection rate: 0.7871352785145889  \n",
    "\n",
    "UNet_80_double_bilinear:  \n",
    "Validation dice score: 0.4426659047603607, Detection rate: 0.8292772861356932  \n",
    "Test dice score: 0.42389044165611267, Detection rate: 0.7791777188328912  \n",
    "\n",
    "Validation dice score: 0.43791401386260986, Detection rate: 0.8547197640117994  \n",
    "Test dice score: 0.42553234100341797, Detection rate: 0.8017241379310345  \n",
    "epoch 17:  \n",
    "Validation dice score: 0.45137089490890503, Detection rate: 0.8521386430678466  \n",
    "Test dice score: 0.4385537803173065, Detection rate: 0.8090185676392573  \n",
    "\n",
    "Validation dice score: 0.4148973822593689, Detection rate: 0.8639380530973452  \n",
    "Test dice score: 0.4070836901664734, Detection rate: 0.8246021220159151\n",
    "\n",
    "UNet_80_double_nearest:  \n",
    "Validation dice score: 0.45902019739151, Detection rate: 0.8174778761061947  \n",
    "Test dice score: 0.44664859771728516, Detection rate: 0.7712201591511937\n",
    "\n",
    "Validation dice score: 0.44770652055740356, Detection rate: 0.8547197640117994  \n",
    "Test dice score: 0.43240076303482056, Detection rate: 0.7967506631299734\n",
    "\n",
    "UNet_80_triple_nearest:  \n",
    "Validation dice score: 0.43449652194976807, Detection rate: 0.8488200589970502  \n",
    "Test dice score: 0.42631348967552185, Detection rate: 0.7950928381962865\n",
    "\n",
    "Validation dice score: 0.44476252794265747, Detection rate: 0.8528761061946902  \n",
    "Test dice score: 0.4263116717338562, Detection rate: 0.7891246684350133\n",
    "\n",
    "UNet_80_triple_bilinear:\n",
    "Validation dice score: 0.44418731331825256, Detection rate: 0.859882005899705  \n",
    "Test dice score: 0.4293147325515747, Detection rate: 0.8252652519893899\n",
    "\n",
    "Validation dice score: 0.45098742842674255, Detection rate: 0.8447640117994101  \n",
    "Test dice score: 0.43127065896987915, Detection rate: 0.7911140583554377\n",
    "\n",
    "UNet_80_double_triple_conv:  \n",
    "Validation dice score: 0.43232494592666626, Detection rate: 0.8668879056047197  \n",
    "Test dice score: 0.4190724790096283, Detection rate: 0.8272546419098143\n",
    "\n",
    "UNet_80_double_triple_bilinear:  \n",
    "Validation dice score: 0.44077542424201965, Detection rate: 0.8366519174041298  \n",
    "Test dice score: 0.428361177444458, Detection rate: 0.7745358090185677\n",
    "\n",
    "UNet_80_double_no_relu_conv:  \n",
    "Validation dice score: 0.42527180910110474, Detection rate: 0.7614306784660767\n",
    "Test dice score: 0.41641998291015625, Detection rate: 0.7178381962864722"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
