{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hogy scaleljük fel a 80x80-as bioszenzor képeket kb 4000x4000-esre?  \n",
    "Olyan érzésem van hogy ez fontosabb mint maga a modell mert ha a scsaling jó akkor kb adatot \"nyerünk\" a képekből és könnyebb dolga lesz a modellnek  \n",
    "Plusz 3D-s a tehát ez is egy plusz dimenzót ad a scalelésnek. Minden idődimben csak a 2D-s képet scaleljük fel? Vagy a teljes 3D-s tenzort? Esetleg az egészből csinálunk egy 4000x4000-es 2D-s képet? Már ha lehet ilyet csinálni.Ehhez lehet egy külön modell kell.\n",
    "\n",
    "Plusz az idődimenzió is nagyon eltérő:  \n",
    "mean: 984.0777777777778  \n",
    "std: 245.44061186082735  \n",
    "min: 642  \n",
    "max: 1418  \n",
    "\n",
    "maszkok statisztikái (mekkora legyen a standard méret?):  \n",
    "mean:4158.277777777777  \n",
    "std: 87.17989418792205  \n",
    "min: 3566  \n",
    "max: 4253  \n",
    "\n",
    "Tehát kb 4000/80=50-szeresére kellene növelni a képeket.\n",
    "\n",
    "Lehetőségek:\n",
    "- interpoláció: ez a leggyorsabb, de a legrosszabb minőségű is, nagyon sok fajtája van, pl. nearest, linear, cubic, area, lanczos  \n",
    "- deep learning: pl. GAN, autoencoder?, de ez a leglassabb, és a legnehezebb de talán jobb eredményt ad  \n",
    "Az esetleges pipelineba nem lehet olyan rétegeket/modellt belerakni ami scalel? Vagy lehet olyat hogy a 80x80-as képet adjuk be és 4000x4000-est várunk?\n",
    "\n",
    "\n",
    "(kézi skálázás: ez a leglassabb, de a legjobb minőségű is)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ötletek:  \n",
    "A 3Ds adatsorból egy 4000x4000-es 2D-s képet csinálunk, majd simán tanítunk rá egy modellt a meglévő maszkokkal.  \n",
    "Az átalakítás a kérdéses hogy hogyan nem vesztünk információt és kapjuk a legjobb képet.  \n",
    "Interpoláció lehetne egy lépés:  \n",
    "- A 3D-a adatsorból egyből egy 4000x4000-es 2D-s képet csinálunk. Egy lépésben nem hiszem hogy van ilyen interpoláció.  \n",
    "- A 3D-s adatsorból egyből egy 2Ds képet csinálunk, majd ezt skálázzuk fel 4000x4000-esre  \n",
    "- Egy vagy pár framet választunk és csak azt interpoláljuk fel 4000x4000-esre  \n",
    "- Saját ötlet hogy kiválasztunk random 50 framet az értékeket összeadjuk majd szétosztjuk 4000x4000-esre. Így a data augmentation is megvan.\n",
    "\n",
    "Vagy valamilyen konvolúciós hálóval megpróbálunk a 3D-s adatsorból egyből egy 4000x4000-es 2D-s képet csinálni.  \n",
    "\n",
    "Vagy csak egy hálót használunk aminek a bemenete 80x80x700 és a kimenete 4000x4000.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adatok egységesítése - milyen módszer? az összes maszk legyen egyforma ->  \n",
    "levágjuk akkor nem biztos hogy jól ráillik a képre  \n",
    "ha scaleljük akkor deformálódhat  \n",
    "\n",
    "a timeseries egyes képeit felscalelni interpolációval? melyik fajta? ezzel szívesen kísérletezek (esetleg átalakítani meglévő algoritmusokat / újat kitalálni)  \n",
    "mekkorára? maszk méret az 50x vagy elég kissebb?  \n",
    "hány időpontot/képet? 1, 50, 500, az összes?  \n",
    "és akkor erre/ezekre a képekre modellt alkotni  \n",
    "\n",
    "vagy nem nagyon piszkálni az adatokat hanem nyersen 80x80-asan beadni a modelnek  \n",
    "ebben az esetben a timeseries egy nagyobb részét/egészét szeretnénk inputként hogy legyen plusz információ a modellnek  \n",
    "az egészet nem  választhatjuk mindenhol mert van ami kétszer olyan hosszú mint egy másik  \n",
    "\n",
    "esetleg LSTM-es encoder megoldás?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Milyen transzformációk kellenek?\n",
    "- Downsampling: 4000x4000 -> 80x80 \n",
    "- Meg a bioszenzorból egyenletes elozslasztású sorozatokat kivenni, 500-1400 képből X darab\n",
    "- Upsampling: 80x80 -> 4000x4000???\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/mehran66/Interpolation-in-Matlab\n",
    "https://github.com/Qirias/Python-Image-Upscaler\n",
    "https://github.com/ShambhawiVarchasva/Image-Scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('your_image.jpg')\n",
    "res = cv2.resize(img, dsize=(54, 140), interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "It does not make good use of Numpy and, thus, is not fast, especially for large images. If you're only rescaling smaller images, it should be fine. I offer this under Apache or MIT license at the discretion of the user.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import numpy\n",
    "\n",
    "def resize_linear(image_matrix, new_height:int, new_width:int):\n",
    "    \"\"\"Perform a pure-numpy linear-resampled resize of an image.\"\"\"\n",
    "    output_image = numpy.zeros((new_height, new_width), dtype=image_matrix.dtype)\n",
    "    original_height, original_width = image_matrix.shape\n",
    "    inv_scale_factor_y = original_height/new_height\n",
    "    inv_scale_factor_x = original_width/new_width\n",
    "\n",
    "    # This is an ugly serial operation.\n",
    "    for new_y in range(new_height):\n",
    "        for new_x in range(new_width):\n",
    "            # If you had a color image, you could repeat this with all channels here.\n",
    "            # Find sub-pixels data:\n",
    "            old_x = new_x * inv_scale_factor_x\n",
    "            old_y = new_y * inv_scale_factor_y\n",
    "            x_fraction = old_x - math.floor(old_x)\n",
    "            y_fraction = old_y - math.floor(old_y)\n",
    "\n",
    "            # Sample four neighboring pixels:\n",
    "            left_upper = image_matrix[math.floor(old_y), math.floor(old_x)]\n",
    "            right_upper = image_matrix[math.floor(old_y), min(image_matrix.shape[1] - 1, math.ceil(old_x))]\n",
    "            left_lower = image_matrix[min(image_matrix.shape[0] - 1, math.ceil(old_y)), math.floor(old_x)]\n",
    "            right_lower = image_matrix[min(image_matrix.shape[0] - 1, math.ceil(old_y)), min(image_matrix.shape[1] - 1, math.ceil(old_x))]\n",
    "\n",
    "            # Interpolate horizontally:\n",
    "            blend_top = (right_upper * x_fraction) + (left_upper * (1.0 - x_fraction))\n",
    "            blend_bottom = (right_lower * x_fraction) + (left_lower * (1.0 - x_fraction))\n",
    "            # Interpolate vertically:\n",
    "            final_blend = (blend_top * y_fraction) + (blend_bottom * (1.0 - y_fraction))\n",
    "            output_image[new_y, new_x] = final_blend\n",
    "\n",
    "    return output_image"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
