{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wittd\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.measure\n",
    "import scipy.ndimage\n",
    "\n",
    "from src.datasets import BiosensorDataset, create_datasets\n",
    "from src.unet import UNet\n",
    "from src.train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "data_path = 'data_with_centers/'\n",
    "checkpoint_dir = 'checkpoints'\n",
    "train_percent = 0.495\n",
    "test_percent = 0.30\n",
    "bio_len = 8\n",
    "mask_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = create_datasets(data_path, train_percent, bool, test_percent=test_percent, biosensor_length=bio_len, mask_size=mask_size, augment=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = UNet(n_channels=bio_len, n_classes=1)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training:\n",
      "        Epochs:          15\n",
      "        Batch size:      4\n",
      "        Learning rate:   0.01\n",
      "        Training size:   80\n",
      "        Validation size: 35\n",
      "        Device:          cuda\n",
      "        Mixed Precision: True\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 80/80 [00:17<00:00,  4.48img/s, loss (batch)=0.964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.22224418818950653, Detection rate: 0.26591075347476223\n",
      "Checkpoint 1 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 80/80 [00:20<00:00,  3.93img/s, loss (batch)=0.73] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.2949659526348114, Detection rate: 0.5596196049743964\n",
      "Checkpoint 2 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 80/80 [00:15<00:00,  5.05img/s, loss (batch)=0.732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.33627158403396606, Detection rate: 0.6221653255303584\n",
      "Checkpoint 3 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 80/80 [00:15<00:00,  5.03img/s, loss (batch)=0.812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.37752917408943176, Detection rate: 0.6850768105340161\n",
      "Checkpoint 4 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 80/80 [00:15<00:00,  5.11img/s, loss (batch)=0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.4066203534603119, Detection rate: 0.7468910021945867\n",
      "Checkpoint 5 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 80/80 [00:16<00:00,  4.92img/s, loss (batch)=0.719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.40421998500823975, Detection rate: 0.7220190197512801\n",
      "Checkpoint 6 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 80/80 [00:15<00:00,  5.08img/s, loss (batch)=0.641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.3515399992465973, Detection rate: 0.7688368690563278\n",
      "Checkpoint 7 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 80/80 [00:15<00:00,  5.01img/s, loss (batch)=0.677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.41272488236427307, Detection rate: 0.7790782735918069\n",
      "Checkpoint 8 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 80/80 [00:15<00:00,  5.22img/s, loss (batch)=0.806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.4202784597873688, Detection rate: 0.7735918068763716\n",
      "Checkpoint 9 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████| 80/80 [00:15<00:00,  5.05img/s, loss (batch)=0.832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.4374597370624542, Detection rate: 0.8068763716166789\n",
      "Checkpoint 10 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████| 80/80 [00:15<00:00,  5.04img/s, loss (batch)=0.79] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.4307698905467987, Detection rate: 0.8072421360643746\n",
      "Checkpoint 11 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|██████████| 80/80 [00:15<00:00,  5.01img/s, loss (batch)=0.78] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.39706456661224365, Detection rate: 0.768471104608632\n",
      "Checkpoint 12 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|██████████| 80/80 [00:15<00:00,  5.08img/s, loss (batch)=0.727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.3975202143192291, Detection rate: 0.8134601316752011\n",
      "Checkpoint 13 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|██████████| 80/80 [00:15<00:00,  5.05img/s, loss (batch)=0.96] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.39990654587745667, Detection rate: 0.7761521580102414\n",
      "Checkpoint 14 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|██████████| 80/80 [00:15<00:00,  5.09img/s, loss (batch)=0.744]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice score: 0.39153358340263367, Detection rate: 0.7937088514996342\n",
      "Checkpoint 15 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_model(\n",
    "        model,\n",
    "        device,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        learning_rate=0.01,\n",
    "        epochs=15,\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        amp=True,\n",
    "        wandb_logging=False\n",
    "    )\n",
    "except torch.cuda.OutOfMemoryError:\n",
    "    torch.cuda.empty_cache()\n",
    "    print('Detected OutOfMemoryError!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(n_channels=8, n_classes=1)\n",
    "checkpoint = torch.load(\"checkpoints/checkpoint_8_4_85.pth\")\n",
    "lr = checkpoint.pop('learning_rate')\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "torch.save(model, 'saved_models/unet_len8.pth')\n",
    "torch.jit.script(model).save('saved_models/unet_len8.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet\n",
      "UNet(\n",
      "  (inc): DoubleConv(\n",
      "    (double_conv): Sequential(\n",
      "      (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (down1): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down2): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down3): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down4): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up1): Up(\n",
      "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up2): Up(\n",
      "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up3): Up(\n",
      "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up4): Up(\n",
      "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (outc): OutConv(\n",
      "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "m = torch.load('saved_models/unet_len8.pth')\n",
    "\n",
    "# Print the model architecture\n",
    "print(m.__class__.__name__)\n",
    "print(m)\n",
    "\n",
    "# List all parameters\n",
    "# for name, param in m.named_parameters():\n",
    "#     print(name, param.shape)\n",
    "\n",
    "# Model summary (requires torchsummary package)\n",
    "# from torchsummary import summary\n",
    "# m.to(device)\n",
    "# summary(m, input_size=(8, 80, 80))  # Adjust input_size as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(\"checkpoints/checkpoint_epoch15.pth\")\n",
    "\n",
    "# Get the learning rate and remove it from the checkpoint\n",
    "lr = checkpoint.pop('learning_rate')\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Print the model summary\n",
    "# summary(model, input_size=(bio_len, mask_size, mask_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a batch of data and labels\n",
    "loader_iter = iter(test_loader)\n",
    "data, labels = next(loader_iter)\n",
    "data, labels = next(loader_iter)\n",
    "data, labels = next(loader_iter)\n",
    "\n",
    "# Move the data and labels to the device\n",
    "data = data.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Get the predictions\n",
    "predictions = model(data)\n",
    "\n",
    "# Move the predictions and labels to the CPU and convert them to numpy arrays\n",
    "predictions = predictions.cpu().detach().numpy()\n",
    "threshold = 0.5\n",
    "binary_predictions = (predictions > threshold).astype(np.uint8)\n",
    "\n",
    "\n",
    "labels = labels.cpu().numpy()\n",
    "\n",
    "# Plot the data, the labels, and the predictions\n",
    "for i in range(len(data)):\n",
    "    plt.figure(figsize=(10, 40))\n",
    "    \n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(data[i].cpu().numpy()[-1], cmap='gray')\n",
    "    plt.title('Biosensor')\n",
    "    \n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(np.squeeze(labels[i]), cmap='gray')\n",
    "    plt.title('True Mask')\n",
    "    \n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(np.squeeze(predictions[i]), cmap='gray')\n",
    "    plt.title('Prediction')\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(np.squeeze(binary_predictions[i]), cmap='gray')\n",
    "    plt.title('Binary Prediction')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data, the labels, and the predictions\n",
    "for i in range(len(data)):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(data[i].cpu().numpy()[-1], cmap='gray')\n",
    "    plt.title('Data')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(data[i].cpu().numpy()[-1], cmap='gray')\n",
    "    plt.imshow(np.squeeze(labels[i]), cmap='jet', alpha=0.5)\n",
    "    plt.title('Data with Label overlay')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(data[i].cpu().numpy()[-1], cmap='gray')\n",
    "    plt.imshow(np.squeeze(binary_predictions[i]), cmap='jet', alpha=0.5)\n",
    "    plt.title('Data with Binary Prediction overlay')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the label and the prediction\n",
    "for i in range(len(labels)):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(np.squeeze(labels[i]), cmap='gray')\n",
    "    plt.title('Label')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(np.squeeze(labels[i]), cmap='gray')\n",
    "    plt.imshow(np.squeeze(binary_predictions[i]), cmap='jet', alpha=0.5)\n",
    "    plt.title('Label with Prediction overlay')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_detection_skimage(model, val_loader, device, threshold=0.5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    total_cells = 0\n",
    "    detected_cells = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for data, labels in val_loader:\n",
    "            # Move the data and labels to the device\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Get the predictions\n",
    "            predictions = model(data)\n",
    "\n",
    "            # Move the predictions and labels to the CPU and convert them to numpy arrays\n",
    "            predictions = predictions.cpu().detach().numpy()\n",
    "            binary_predictions = (predictions > threshold).astype(np.uint8)\n",
    "\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            for i in range(len(data)):\n",
    "                # Label the binary prediction and count the number of cells\n",
    "                _, num_cells_pred = skimage.measure.label(binary_predictions[i], return_num=True, connectivity=2)\n",
    "                _, num_cells_label = skimage.measure.label(labels[i], return_num=True, connectivity=2)\n",
    "\n",
    "                total_cells += num_cells_label\n",
    "                detected_cells += num_cells_pred\n",
    "\n",
    "    cell_detection_rate = detected_cells / total_cells if total_cells > 0 else 0\n",
    "\n",
    "    return cell_detection_rate, total_cells, detected_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_detection_scipy(model, val_loader, device, threshold=0.5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    total_cells = 0\n",
    "    detected_cells = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for data, labels in val_loader:\n",
    "            # Move the data and labels to the device\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Get the predictions\n",
    "            predictions = model(data)\n",
    "\n",
    "            # Move the predictions and labels to the CPU and convert them to numpy arrays\n",
    "            predictions = predictions.cpu().detach().numpy()\n",
    "            binary_predictions = (predictions > threshold).astype(np.uint8)\n",
    "\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            structure = np.ones((3, 3))\n",
    "\n",
    "            for i in range(len(data)):\n",
    "                # Label the binary prediction and count the number of cells\n",
    "                _, num_cells_pred = scipy.ndimage.label(np.squeeze(binary_predictions[i]), structure=structure)\n",
    "                _, num_cells_label = scipy.ndimage.label(labels[i], structure=structure)\n",
    "\n",
    "                total_cells += num_cells_label\n",
    "                detected_cells += num_cells_pred\n",
    "\n",
    "    cell_detection_rate = detected_cells / total_cells if total_cells > 0 else 0\n",
    "\n",
    "    return cell_detection_rate, total_cells, detected_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_pixels(model, val_loader, device, threshold=0.5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    total_cells = 0\n",
    "    detected_cells = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for data, labels in val_loader:\n",
    "            # Move the data and labels to the device\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Get the predictions\n",
    "            predictions = model(data)\n",
    "\n",
    "            # Move the predictions and labels to the CPU and convert them to numpy arrays\n",
    "            predictions = predictions.cpu().detach().numpy()\n",
    "            binary_predictions = (predictions > threshold).astype(np.uint8)\n",
    "\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            total_cells += np.sum(labels)\n",
    "            detected_cells += np.sum(binary_predictions)\n",
    "\n",
    "    return total_cells, detected_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9485 6677\n"
     ]
    }
   ],
   "source": [
    "label, detected = pos_pixels(model, test_loader, device, threshold=0.5)\n",
    "print(label, detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell detection rate: 0.7451589768109013, total cells: 4183, detected cells: 3117\n"
     ]
    }
   ],
   "source": [
    "cell_detection_rate, total, detected = cell_detection_skimage(model, test_loader, device)\n",
    "print(f'Cell detection rate: {cell_detection_rate}, total cells: {total}, detected cells: {detected}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell detection rate: 0.7726512072675114, total cells: 4183, detected cells: 3232\n"
     ]
    }
   ],
   "source": [
    "cell_detection_rate, total, detected = cell_detection_scipy(model, test_loader, device)\n",
    "print(f'Cell detection rate: {cell_detection_rate}, total cells: {total}, detected cells: {detected}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
